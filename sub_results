score	model				data		fp16	paras			split_num	dropout
0.7999	RoBERTa_large+guoday		original	False	epoch3 _bs64_lr5e-5	1		0.1
0.8112	RoBERTa_large+guoday		original	False	epoch3 _bs64_lr5e-5	3		0.1
0.7991	RoBERTa_large+guoday            original        False   epoch10_bs64_lr5e-5     1		0.1
0.8020	RoBERTa_large+guoday            original        False   epoch10_bs64_lr5e-5     3		0.1

	RoBERTa_large+guoday            original        False   epoch5 _bs64_lr5e-5     3               0.1	# epoch num matters?

0.7873	RoBERTa_large+guoday            original        False   epoch3 _bs32_lr5e-5     3		0.1	# batch size matters?
0.8060	RoBERTa_large+guoday            original        False   epoch3 _bs128_lr5e-5    3               0.1

	RoBERTa_large+guoday            original        False   epoch3 _bs64_lr5e-6	3		0.1	# learning rate matters?

	RoBERTa_large+guoday            original        False   epoch_bs_lr5e-6     	3		0.1
	RoBERTa_large+guoday            original        False   epoch_bs_lr5e-6     	1		0.1
	RoBERTa_large+guoday            original        False   epoch_bs_lr5e-6     	3		0.1

	RoBERTa_large+guoday            original        False   epoch_bs_lr5e-6		3		0.1
	RoBERTa_large+guoday            original        False   epoch_bs_lr5e-6		3		0.1


	RoBERTa_large+MLP		original	False	epoch10_bs32_lr5e-5	1		0.1
	RoBERTa_large+GRU		original	False	epoch10_bs32_lr5e-5	1		0.1
